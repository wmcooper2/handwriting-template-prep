{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141812970 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sliced:  Version6Results/jpg/1.jpg\n",
      "Sliced:  Version6Results/jpg/2.jpg\n",
      "Sliced:  Version6Results/jpg/3.jpg\n",
      "Sliced:  Version6Results/jpg/4.jpg\n",
      "Sliced:  Version6Results/jpg/5.jpg\n",
      "Sliced:  Version6Results/jpg/6.jpg\n",
      "Sliced:  Version6Results/jpg/7.jpg\n",
      "Sliced:  Version6Results/jpg/8.jpg\n",
      "Sliced:  Version6Results/jpg/9.jpg\n",
      "Sliced:  Version6Results/jpg/10.jpg\n",
      "Sliced:  Version6Results/jpg/11.jpg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66b859b428ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# give the computer a chance to cool down during a large run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "class SlicingTemplate:\n",
    "    def __init__(self):\n",
    "        self.image_file = None  # posix path\n",
    "        self.img = None  # actual image\n",
    "        self.counter = None\n",
    "        self.save_dir = None\n",
    "        \n",
    "        self.left = 0\n",
    "        self.x1 = 330\n",
    "        self.x2 = 470\n",
    "        self.x3 = 990\n",
    "        self.right = None  # set in self.load()\n",
    "        \n",
    "        self.top = 0\n",
    "        self.y1 = 110\n",
    "        self.y2 = 235\n",
    "        self.y3 = 360\n",
    "        self.y4 = 510\n",
    "        self.bottom = None  # set in self.load()\n",
    "        \n",
    "    # This method was adapted from the original, just for this notebook\n",
    "    def single_image_process(self):\n",
    "        self.img = Image.open(str(self.image_file)) # convert to cv2 later...\n",
    "        self.right = self.img.size[0]  # image width\n",
    "        self.bottom = self.img.size[1]  # image height\n",
    "        self.setup_sections()\n",
    "        \n",
    "        # crop out the parts based on the (manually set) template's dimensions\n",
    "        for section in self.major_sections:\n",
    "            for dir_name, box in section.items():\n",
    "                cropped_img = self.img.crop((box[\"left\"], box[\"top\"], box[\"right\"], box[\"bottom\"]))\n",
    "                file_name = path.join(self.save_dir, dir_name, str(self.counter)+\".jpg\")\n",
    "                cropped_img.save(file_name)\n",
    "        \n",
    "    def setup_sections(self):\n",
    "        # these are the box boundaries for each section, manually set\n",
    "        self.major_sections = [\n",
    "            {\"uppercase\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.top,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y1}\n",
    "            },\n",
    "            {\"lowercase\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y1,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y2}\n",
    "            },\n",
    "            {\"digits\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y2,\n",
    "                \"right\": self.x2,\n",
    "                \"bottom\": self.y3}\n",
    "            },\n",
    "            {\"punctuation\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y2,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y3}\n",
    "            },\n",
    "            {\"sent1\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y3,\n",
    "                \"right\": self.x1,\n",
    "                \"bottom\": self.y4}\n",
    "            },\n",
    "            {\"sent2\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y3,\n",
    "                \"right\": self.x3,\n",
    "                \"bottom\": self.y4}\n",
    "            },\n",
    "            {\"sent3\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y4,\n",
    "                \"right\": self.x1,\n",
    "                \"bottom\": self.bottom}\n",
    "            },\n",
    "            {\"sent4\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y4,\n",
    "                \"right\": self.x3,\n",
    "                \"bottom\": self.bottom}\n",
    "            }\n",
    "        ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "IMG_DIR = Path(\"Samples\")\n",
    "CROPPED_DIR = Path(\"Version6Results/cropped\")\n",
    "JPG_DIR = Path(\"Version6Results/jpg\")\n",
    "SLICE_DIR = Path(\"Version6Results/slices\")\n",
    "\n",
    "counter = 1\n",
    "for picture in IMG_DIR.iterdir():\n",
    "    if counter % 3 == 0:\n",
    "        print(\"cool down\")\n",
    "        sleep(120) # chance to cool down during large runs\n",
    "        \n",
    "    if picture.suffix in [\".jpg\", \".jpeg\", \".png\"]:\n",
    "        file_name = str(counter)+\".jpg\"\n",
    "        file_path = path.join(Path(JPG_DIR, file_name))\n",
    "        save_name = str(file_path)\n",
    "        BW = \"L\"\n",
    "        new_img = Image.open(str(picture)).convert(BW) #change to cv2 cvtColor, then remove pillow import\n",
    "        new_img.save(file_path)\n",
    "        actual_img = Image.open(save_name)\n",
    "        width = actual_img.size[0]\n",
    "        height = actual_img.size[1]\n",
    "        \n",
    "#Rotate\n",
    "        # rotate to landscape if needed, don't yet know up or down\n",
    "        if width < height:\n",
    "            rotated = actual_img.rotate(90, expand=True)\n",
    "        else:\n",
    "            rotated = actual_img\n",
    "        rotated.save(save_name)\n",
    "\n",
    "        # load images\n",
    "        TEMPLATE = \"template.jpg\"\n",
    "        template_img = cv2.imread(TEMPLATE, 1) #1 is grayscale enum flag\n",
    "        target_img = cv2.imread(save_name, 1)\n",
    "\n",
    "        # cropping box to reduce search area for target template\n",
    "        left = 8500\n",
    "        top = 8000\n",
    "        right = left + 700\n",
    "        bottom = top + 700\n",
    "\n",
    "        # get the target image from the template\n",
    "        # crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "        cropped_img = target_img[top:bottom, left:right]\n",
    "        method = cv2.TM_SQDIFF_NORMED  \n",
    "        result = cv2.matchTemplate(template_img, cropped_img, method) \n",
    "\n",
    "        # minimum squared difference; image similarity score is maxVal\n",
    "        mn, maxVal, mnLoc, maxLoc = cv2.minMaxLoc(result)  \n",
    "\n",
    "        # exaggerate the values to make it easier to set a cutoff point\n",
    "        score = round((maxVal*100)*(maxVal*100))\n",
    "        \n",
    "        # 9500 points seems to be a good cutoff\n",
    "        if score < 9500:\n",
    "            upright_image = cv2.rotate(target_img, cv2.ROTATE_180)\n",
    "        else:\n",
    "            upright_image = target_img\n",
    "        cv2.imwrite(save_name, upright_image)\n",
    "\n",
    "#Crop\n",
    "        # cropping box to reduce search area for target template\n",
    "        left = 850\n",
    "        top = 710\n",
    "        right = 12560\n",
    "        bottom = 7300\n",
    "\n",
    "        img = cv2.imread(save_name, 1) #1 is grayscale enum flag        \n",
    "        img = img[top:bottom, left:right]\n",
    "\n",
    "#Downscale\n",
    "        # calculate new size\n",
    "        SCALE_PERCENT = 10 # percent of original size\n",
    "        width = int(img.shape[1] * SCALE_PERCENT / 100)\n",
    "        height = int(img.shape[0] * SCALE_PERCENT / 100)\n",
    "        new_size = (width, height)\n",
    "\n",
    "        # resize image\n",
    "        img = cv2.resize(img, new_size, interpolation = cv2.INTER_AREA)\n",
    "        cv2.imwrite(save_name, img)\n",
    "\n",
    "\n",
    "#Threshold\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # redundant?\n",
    "        gray = cv2.bitwise_not(img) # for the threshold function only\n",
    "\n",
    "        # threshold the image, setting all foreground pixels to 255 and all background pixels to 0\n",
    "        thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "#Deskew\n",
    "        # grab the (x, y) coordinates of all pixel values that are greater than zero, then use these coordinates to\n",
    "        # compute a rotated bounding box that contains all coordinates\n",
    "        coords = np.column_stack(np.where(thresh > 0))\n",
    "        angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "        # the `cv2.minAreaRect` function returns values in the range [-90, 0); as the rectangle rotates clockwise \n",
    "        # the returned angle trends to 0 -- in this special case we need to add 90 degrees to the angle\n",
    "        if angle < -45:\n",
    "            angle = -(90 + angle)\n",
    "\n",
    "        # otherwise, just take the inverse of the angle to make it positive\n",
    "        else:\n",
    "            angle = -angle\n",
    "\n",
    "        # rotate the image to deskew it\n",
    "        (h, w) = img.shape[:2]\n",
    "        center = (w // 2, h // 2)\n",
    "        M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "        deskewd = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "        cv2.imwrite(save_name, deskewd)\n",
    "\n",
    "#Slicing\n",
    "        # extract major sections from each image\n",
    "        slicer = SlicingTemplate()\n",
    "        slicer.image_file = file_path # pass a path object to the class\n",
    "        slicer.image_file = Path(save_name) # pass a path object to the class\n",
    "        \n",
    "        slicer.save_dir = str(SLICE_DIR)\n",
    "        slicer.counter = counter\n",
    "        slicer.single_image_process()\n",
    "        \n",
    "        print(\"Sliced: \", file_path)\n",
    "        counter += 1            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
