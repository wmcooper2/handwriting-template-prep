{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different order\n",
    "Trying to increase effectiveness and efficiency.\n",
    "\n",
    "1. downscale and resave as JPG\n",
    "2. rotate to landscape\n",
    "3. orient upright\n",
    "4. deskew\n",
    "5. crop to first outer edges using Canny outlines\n",
    "6. split into 8 major sections\n",
    "7. slice up the letters based on a simple, manually generated template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv colors, for convenience\n",
    "BLUE = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "BLACK = (0, 0, 0)\n",
    "PURPLE = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. downscale and resave as JPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything below this point is run as a single pass through a loop.  \n",
    "Each image will be:  \n",
    "1. Converted to JPG\n",
    "2. Oriented right side up.\n",
    "3. Downscaled\n",
    "4. Cropped\n",
    "5. Cut into 8 major sections.\n",
    "6. Saved into 8 separate dirs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the image file\n",
    "BATCH_DIR = Path(\"BatchProcess\")\n",
    "ORIGINAL = \"original.jpeg\"\n",
    "img_path = Path(BATCH_DIR, ORIGINAL)\n",
    "old = str(img_path)\n",
    "old_name = str(img_path.name)\n",
    "new_name = old_name.rstrip(str(img_path.suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141812970 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    }
   ],
   "source": [
    "# load the image and convert to grayscale\n",
    "new_img = Image.open(img_path).convert(\"L\") # L is grayscale or \"luminance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a JPG\n",
    "JPG_IMG = new_name+\".jpg\"\n",
    "name = path.join(BATCH_DIR, JPG_IMG)\n",
    "new_img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 141812970 bytes, downscaled: 1417422 bytes\n"
     ]
    }
   ],
   "source": [
    "# downscale\n",
    "SCALE_PERCENT = 10 # percent of original size\n",
    "\n",
    "# open the JPG, not JPEG\n",
    "img_path = Path(BATCH_DIR, JPG_IMG)\n",
    "img_name = str(img_path)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# calculate new size\n",
    "width = int(img.shape[1] * SCALE_PERCENT / 100)\n",
    "height = int(img.shape[0] * SCALE_PERCENT / 100)\n",
    "new_size = (width, height)\n",
    "\n",
    "# downscale image\n",
    "DOWNSCALED = \"downscaled.jpg\"\n",
    "downscaled = cv2.resize(img, new_size, interpolation = cv2.INTER_AREA)\n",
    "file_name = str(Path(BATCH_DIR, DOWNSCALED))\n",
    "cv2.imwrite(file_name, downscaled)\n",
    "\n",
    "# print(f\"Original: {img.nbytes} bytes, downscaled: {downscaled.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The images may be in any rotation of 90 degrees.  \n",
    "This one happens to have the top at the left edge.\n",
    "![](BatchProcess/downscaled.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. rotate to landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the downscaled image\n",
    "img_path = Path(BATCH_DIR, DOWNSCALED)\n",
    "img = Image.open(str(img_path))\n",
    "width = img.size[0]\n",
    "height = img.size[1]\n",
    "\n",
    "# rotate to landscape if needed, don't yet know rightsideup or upsidedown\n",
    "if width < height:\n",
    "    landscaped = img.rotate(90, expand=True)\n",
    "LANDSCAPED = \"landscaped.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, LANDSCAPED))\n",
    "landscaped.save(file_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A simple rotation based on the fact that the width needs to be greater than the height.  \n",
    "This one happens to be upside down.\n",
    "![](BatchProcess/landscaped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. orient upright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template image\n",
    "# the template image was selected manually by using the GIMP editor\n",
    "TEMPLATE = \"template.jpg\"\n",
    "img_path = Path(BATCH_DIR, TEMPLATE)\n",
    "template = str(img_path)\n",
    "template_img = cv2.imread(template, 1) #1 is grayscale enum flag"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The template is the image that is being searched for in another image.  \n",
    "The template I am searching for is this \"x\" which is unique in a broad area of the image.\n",
    "\n",
    "__template.jpg__  \n",
    "![](BatchProcess/template.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target image\n",
    "img_path = Path(BATCH_DIR, LANDSCAPED)\n",
    "target = str(img_path)\n",
    "target_img = cv2.imread(target, 1) #1 is grayscale enum flag\n",
    "\n",
    "# find these dimensions in GIMP\n",
    "#     cropping box to reduce target search area, looking for template\n",
    "left = 845\n",
    "top = 790\n",
    "right = left + 100\n",
    "bottom = top + 100\n",
    "\n",
    "# get the target image area from the template to reduce computational expense\n",
    "#    crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "target_search_area = target_img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template match score: 165\n"
     ]
    }
   ],
   "source": [
    "# calculate the likelihood of a match\n",
    "method = cv2.TM_SQDIFF_NORMED  \n",
    "result = cv2.matchTemplate(template_img, target_search_area, method) \n",
    "\n",
    "# minimum squared difference\n",
    "#    image similarity score is maxVal, which is what I need\n",
    "mn, maxVal, mnLoc, maxLoc = cv2.minMaxLoc(result)  \n",
    "\n",
    "# exaggerate the values to make it easier to set a cutoff point\n",
    "score = round((maxVal*100)**2)\n",
    "print(f\"Template match score: {score}\")\n",
    "\n",
    "# flip and save in place\n",
    "# 600 points seems to be a good cutoff, arbitrarily chosen for now\n",
    "if score < 600:\n",
    "    RIGHT_SIDE_UP = \"rightSideUp.jpg\"\n",
    "    rightsideup = cv2.rotate(target_img, cv2.ROTATE_180)\n",
    "    file_name = str(Path(BATCH_DIR, RIGHT_SIDE_UP))\n",
    "    cv2.imwrite(file_name, rightsideup)\n",
    "else:\n",
    "    # no need to rotate or save as its already in the correct position.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This image was upside down.  \n",
    "The template matching process gave it a low score (below 600) so it needed to be rotated right side up.  \n",
    "\n",
    "__rightSideUp.jpg__  \n",
    "![](BatchProcess/rightSideUp.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle skew: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "img_path = Path(BATCH_DIR, RIGHT_SIDE_UP)\n",
    "img = cv2.imread(str(img_path))\n",
    "\n",
    "# convert to grayscale, flip foreground and background\n",
    "#    foreground is now \"white\" and the background is \"black\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bitwise_not(gray)\n",
    "\n",
    "# threshold the image, setting all foreground pixels to 255 and all background pixels to 0\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# grab the (x, y) coordinates of all pixel values that are greater than zero, then use these coordinates to\n",
    "#    compute a rotated bounding box that contains all coordinates\n",
    "coords = np.column_stack(np.where(thresh > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "# the `cv2.minAreaRect` function returns values in the range [-90, 0); as the rectangle rotates clockwise the\n",
    "#    returned angle trends to 0 -- in this special case we need to add 90 degrees to the angle\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "\n",
    "# otherwise, just take the inverse of the angle to make it positive\n",
    "else:\n",
    "    angle = -angle\n",
    "print(f\"Angle skew: {angle}\")\n",
    "\n",
    "# rotate the image to deskew it\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "DESKEWD = \"deskewd.jpg\"\n",
    "deskewd = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "deskewd_name = str(Path(BATCH_DIR, DESKEWD))\n",
    "cv2.imwrite(deskewd_name, deskewd)\n",
    "\n",
    "# CLEAN_DESKEWD = \"cleanDeskewd.jpg\"\n",
    "# clean_deskewd = deskewd.copy() # for use later, without the contour lines drawn in...\n",
    "# clean_deskewd_name = str(Path(BATCH_DIR, CLEAN_DESKEWD))\n",
    "# cv2.imwrite(clean_deskewd_name, deskewd)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fortunately, this image was not skewed... Need to try it on a badly skewed image.  \n",
    "\n",
    "__deskewd.jpg__  \n",
    "![](BatchProcess/deskewd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. crop to first outer edges using Canny outlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a reduce noise while preserving boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "img_path = Path(BATCH_DIR, DESKEWD)\n",
    "file_name = str(img_path)\n",
    "uppercase_img = cv2.imread(file_name)\n",
    "\n",
    "# convert to grayscale\n",
    "grayscaled = cv2.cvtColor(uppercase_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# bilateralFilter reduces noise while preserving boundaries\n",
    "bilateral_filtered = cv2.bilateralFilter(grayscaled, 11, 17, 17)\n",
    "BILATERAL_FILTERED = \"bilateralFiltered.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, BILATERAL_FILTERED))\n",
    "cv2.imwrite(file_name, bilateral_filtered)\n",
    "\n",
    "\n",
    "#### Dont' use this image going forward. It has the cleanest image (noise reduced) which tricks Canny into ignoring the important borders\n",
    "#### Use the deskewd image...\n",
    "# base_image = bilateral_filtered.copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It doesn't look like much has changed, but the \"noise\" was reduced.\n",
    "\n",
    "__bilateralFiltered.jpg__\n",
    "![](BatchProcess/bilateralFiltered.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b invert the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert the image for making bounding boxes\n",
    "BILATERAL_FILTER_INVERTED = \"bilateralFilteredInverted.jpg\"\n",
    "# bilateral_filter_inverted = cv2.bitwise_not(gray)\n",
    "bilateral_filter_inverted = cv2.bitwise_not(bilateral_filtered)\n",
    "file_name = str(Path(BATCH_DIR, BILATERAL_FILTER_INVERTED))\n",
    "cv2.imwrite(file_name, bilateral_filter_inverted)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Inverting the black and white helps the Canny function find the edges.\n",
    "With the image inverted, it is easier to see that the noise was reduced.  \n",
    "If you zoom in on the original image, you would see where the black printer ink scatters around the characters a little.  \n",
    "\n",
    "__bilateralFilteredInverted.jpg__  \n",
    "![](BatchProcess/bilateralFilteredInverted.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5c find the edges with Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get edges\n",
    "CANNY = \"canny.jpg\"\n",
    "canny_edges = cv2.Canny(bilateral_filter_inverted, 30, 200)\n",
    "file_name = str(Path(BATCH_DIR, CANNY))\n",
    "cv2.imwrite(file_name, canny_edges)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Canny function produced white lines where if found the edges.  \n",
    "If you look closely, you can see that the lines that make the characters and borders are thick enough that the Canny function produced two lines; one for each edge of every line of ink in the original image.  \n",
    "\n",
    "__canny.jpg__\n",
    "![](BatchProcess/canny.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5d get the contours of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find contours in the edged image, keep only the largest ones, and initialize our screen contour\n",
    "contours = cv2.findContours(canny_edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = imutils.grab_contours(contours) # convenience function (really simple, see https://github.com/jrosebr1/imutils/blob/master/imutils/convenience.py)\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse=True)[:10]\n",
    "# print(f\"Contours found: {len(contours)}\")\n",
    "# print(f\"Length of first contour: {len(contours[0])}\")\n",
    "# print(type(contours))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "screenCnt = None\n",
    "# loop over our contours\n",
    "for c in contours:\n",
    "    # approximate the contour\n",
    "    epsilon = 0.015 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "    \n",
    "    # if our approximated contour has four points, then we can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "        \n",
    "#### Not sure what this block of code is for..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Feed in the deskewd image\n",
    "CONTOURED = \"contoured.jpg\"\n",
    "# contoured = cv2.drawContours(deskewd, contours, -1, GREEN, 1) #green color shows up here\n",
    "# contoured = cv2.drawContours(bilateral_filtered, contours, -1, GREEN, 1) #green color irrelevant here\n",
    "# file_name = str(Path(BATCH_DIR, CONTOURED))\n",
    "# cv2.imwrite(file_name, contoured)\n",
    "\n",
    "#don't draw the contours, just keep them in memory to be used later"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Although the current parameters for the Canny function didn't produce what I expected (intended), I think it is still of use as it found the edges of the boxes that I will need to crop out.  \n",
    "\n",
    "__contoured.jpg__  \n",
    "![](BatchProcess/contoured.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5e get the edges of the intended cropping area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions\n",
    "def four_corners(box):\n",
    "    xs = [el[0][0] for el in box]\n",
    "    ys = [el[0][1] for el in box]\n",
    "    x_min = min(xs)\n",
    "    x_max = max(xs)\n",
    "    y_min = min(ys)\n",
    "    y_max = max(ys)\n",
    "    return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "def area(corners):\n",
    "    return (corners[1] - corners[0]) * (corners[3] - corners[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "boxes = {}\n",
    "for contour in contours:\n",
    "    box = contours.index(contour)\n",
    "    corners = four_corners(contour)\n",
    "    boxes[box] = {\"area\": area(corners), \"corners\": corners}\n",
    "\n",
    "# pprint(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the minmax across all the box corners\n",
    "xmin = min([values[\"corners\"][0] for box, values in boxes.items()])\n",
    "xmax = max([values[\"corners\"][1] for box, values in boxes.items()])\n",
    "ymin = min([values[\"corners\"][2] for box, values in boxes.items()])\n",
    "ymax = max([values[\"corners\"][3] for box, values in boxes.items()])\n",
    "\n",
    "# print(xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plot the four extremes of the first contour on the deskewd image, not the cropped image\n",
    "#    This step is not needed, but I want to include it to emphasize/illustrate the point about finding the 4 corners using Canny's help\n",
    "upper_left = (xmin, ymin)\n",
    "lower_left = (xmin, ymax)\n",
    "upper_right = (xmax, ymin)\n",
    "lower_right = (xmax, ymax)\n",
    "\n",
    "radius = 10\n",
    "thickness = -1 # negative for filled circle\n",
    "\n",
    "#changed deskewd to bilateral_filtered for the base image\n",
    "four_corners = cv2.circle(bilateral_filtered, upper_left, radius, RED, thickness)\n",
    "four_corners = cv2.circle(bilateral_filtered, upper_right, radius, GREEN, thickness)\n",
    "four_corners = cv2.circle(bilateral_filtered, lower_left, radius, BLUE, thickness)\n",
    "four_corners = cv2.circle(bilateral_filtered, lower_right, radius, BLACK, thickness)\n",
    "FOUR_CORNERS = \"fourCorners.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, FOUR_CORNERS))\n",
    "cv2.imwrite(file_name, four_corners)\n",
    "\n",
    "\n",
    "#### Don't need to draw the dots, I'm not teaching others, I'm just working toward a final goal"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is the image before the cropping.  The four dots show where the corners were calculated using the help of Canny.  \n",
    "\n",
    "__fourCorners.jpg__\n",
    "![](BatchProcess/fourCorners.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crop the image using the minmax of all the contours\n",
    "#    need some padding for the auto crop of the 8 major sections... It's too strict\n",
    "padding = 10\n",
    "left = xmin - padding\n",
    "top = ymin - padding\n",
    "right = xmax + padding\n",
    "bottom = ymax + padding\n",
    "\n",
    "# get the target image from the template\n",
    "#     crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "CROPPED = \"cropped.jpg\"\n",
    "cropped = deskewd[top:bottom, left:right]\n",
    "# cropped = clean_deskewd[top:bottom, left:right]\n",
    "file_name = str(Path(BATCH_DIR, CROPPED))\n",
    "cv2.imwrite(file_name, cropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This is the image after cropping using the contours found with the help of Canny.  \n",
    "You can see that the edges have been cropped very close to the new boundaries and that the unwanted text at the bottom of the image was removed, too.  \n",
    "This should be a cropped version of the noise-reduced (bilateralFilter) image.  \n",
    "\n",
    "__cropped.jpg__\n",
    "![](BatchProcess/cropped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5f crop the image"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CLEANED_CROPPED = \"cleanCropped.jpg\"\n",
    "clean_cropped = clean_deskewd[top:bottom, left:right]\n",
    "file_name = str(Path(BATCH_DIR, CLEANED_CROPPED))\n",
    "cv2.imwrite(file_name, clean_cropped)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Here is the cropped image without the contours drawn in.  \n",
    "From this image, I can slice it up using coordinates found using GIMP.\n",
    "\n",
    "__cleanCropped.jpg__\n",
    "\n",
    "![](BatchProcess/cleanCropped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. split into 8 major sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that I think that I need to crop the largest area of usable content first is that is was needed to make sure the images are aligned and sized properly for the following stages.  \n",
    "From this point, I can just apply a template slicing to the sections to divide everything into 8 major pieces.  \n",
    "Then, on each major piece, assuming the previous steps were successful in aligning everything properly, I can run step 5 (cropping using Canny) again on each of the smaller pieces to maintain the proper sizing and alignment on each smaller piece.  \n",
    "Finally, I can use another template slicing specific to each of the 8 sections to extract the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1171, 658)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the box boundaries for each section, found manually using GIMP\n",
    "left = 0\n",
    "x1 = 330\n",
    "x2 = 470\n",
    "x3 = 990\n",
    "right = cropped.shape[1]  # image width\n",
    "\n",
    "top = 0\n",
    "y1 = 110\n",
    "y2 = 230\n",
    "y3 = 360\n",
    "y4 = 510\n",
    "bottom = cropped.shape[0]  # image height\n",
    "\n",
    "right, bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these 8 sections are the template for slicing up the major parts of the handwriting form\n",
    "major_sections = [\n",
    "    {\"uppercase\": {\n",
    "        \"left\": left,\n",
    "        \"top\": top,\n",
    "        \"right\": right,\n",
    "        \"bottom\": y1}\n",
    "    },\n",
    "    {\"lowercase\": {\n",
    "        \"left\": left,\n",
    "        \"top\": y1,\n",
    "        \"right\": right,\n",
    "        \"bottom\": y2}\n",
    "    },\n",
    "    {\"digits\": {\n",
    "        \"left\": left,\n",
    "        \"top\": y2,\n",
    "        \"right\": x2,\n",
    "        \"bottom\": y3}\n",
    "    },\n",
    "    {\"punctuation\": {\n",
    "        \"left\": x2,\n",
    "        \"top\": y2,\n",
    "        \"right\": right,\n",
    "        \"bottom\": y3}\n",
    "    },\n",
    "    {\"sent1\": {\n",
    "        \"left\": left,\n",
    "        \"top\": y3,\n",
    "        \"right\": x1,\n",
    "        \"bottom\": y4}\n",
    "    },\n",
    "    {\"sent2\": {\n",
    "        \"left\": x2,\n",
    "        \"top\": y3,\n",
    "        \"right\": x3,\n",
    "        \"bottom\": y4}\n",
    "    },\n",
    "    {\"sent3\": {\n",
    "        \"left\": left,\n",
    "        \"top\": y4,\n",
    "        \"right\": x1,\n",
    "        \"bottom\": bottom}\n",
    "    },\n",
    "    {\"sent4\": {\n",
    "        \"left\": x2,\n",
    "        \"top\": y4,\n",
    "        \"right\": x3,\n",
    "        \"bottom\": bottom}\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is a condensed version of the above (step 5)\n",
    "def crop_outer_edges(img):\n",
    "    # convert to grayscale\n",
    "    grayscaled = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # bilateralFilter reduces noise while preserving boundaries\n",
    "    bilateral_filtered = cv2.bilateralFilter(grayscaled, 11, 17, 17)\n",
    "    \n",
    "    # invert the image for making bounding boxes\n",
    "    bilateral_filter_inverted = cv2.bitwise_not(bilateral_filtered)\n",
    "\n",
    "    # get edges\n",
    "    canny_edges = cv2.Canny(bilateral_filter_inverted, 30, 200)\n",
    "    canny_edges = cv2.Canny(img, 30, 200)\n",
    "\n",
    "    # find contours in the edged image, keep only the largest ones\n",
    "    contours = cv2.findContours(canny_edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours) # convenience function (really simple, see https://github.com/jrosebr1/imutils/blob/master/imutils/convenience.py)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:10]\n",
    "\n",
    "    # convenience functions\n",
    "    def four_corners(box):\n",
    "        xs = [el[0][0] for el in box]\n",
    "        ys = [el[0][1] for el in box]\n",
    "        x_min = min(xs)\n",
    "        x_max = max(xs)\n",
    "        y_min = min(ys)\n",
    "        y_max = max(ys)\n",
    "        return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "    def area(corners):\n",
    "        # x1, x2, y1, y2\n",
    "        return (corners[1] - corners[0]) * (corners[3] - corners[2])    \n",
    "\n",
    "    # save the area and corners of the contours for each box\n",
    "    boxes = {}\n",
    "    box_index = 0\n",
    "    for contour in contours:\n",
    "#         box = contours.index(contour)\n",
    "        corners = four_corners(contour)\n",
    "#         boxes[box] = {\"area\": area(corners), \"corners\": corners}\n",
    "        boxes[box_index] = {\"area\": area(corners), \"corners\": corners}\n",
    "        box_index += 1\n",
    "        \n",
    "    # the minmax among all the boxes' corners\n",
    "    xmin = min([values[\"corners\"][0] for box, values in boxes.items()])\n",
    "    xmax = max([values[\"corners\"][1] for box, values in boxes.items()])\n",
    "    ymin = min([values[\"corners\"][2] for box, values in boxes.items()])\n",
    "    ymax = max([values[\"corners\"][3] for box, values in boxes.items()])\n",
    "\n",
    "    # crop the image using the minmax of all the contours\n",
    "    left = xmin\n",
    "    top = ymin\n",
    "    right = xmax\n",
    "    bottom = ymax\n",
    "\n",
    "    # get the target image from the template\n",
    "    return img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice major sections from each image and save in their proper dir\n",
    "#    crop again using canny's help\n",
    "# img_path = Path(BATCH_DIR, clean_cropped)\n",
    "# for image in dir:\n",
    "counter = 0\n",
    "for section in major_sections:\n",
    "    for dir_name, box in section.items():\n",
    "        cropped_img = cropped[box[\"top\"]:box[\"bottom\"], box[\"left\"]:box[\"right\"]]\n",
    "        tighter_crop = crop_outer_edges(cropped_img)\n",
    "        file_name = path.join(\"BatchProcess\", dir_name, str(counter)+\".jpg\")\n",
    "        cv2.imwrite(file_name, tighter_crop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__uppercase__\n",
    "\n",
    "![](BatchProcess/uppercase/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__lowercase__\n",
    "\n",
    "![](BatchProcess/lowercase/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__digits__\n",
    "\n",
    "![](BatchProcess/digits/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__punctuation__\n",
    "\n",
    "![](BatchProcess/punctuation/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__sent1__\n",
    "\n",
    "![](BatchProcess/sent1/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__sent2__\n",
    "\n",
    "![](BatchProcess/sent2/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__sent3__\n",
    "\n",
    "![](BatchProcess/sent3/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__sent4__\n",
    "\n",
    "![](BatchProcess/sent4/0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. slice up the letters based on a simple, manually generated template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These values were found manually by using GIMP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
