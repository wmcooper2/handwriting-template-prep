{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different order\n",
    "Trying to increase effectiveness and efficiency.\n",
    "\n",
    "1. downscale and resave as JPG\n",
    "2. rotate to landscape\n",
    "3. orient upright\n",
    "4. deskew\n",
    "5. crop to first outer edges using Canny outlines\n",
    "6. split into 8 major sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. downscale and resave as JPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the image file\n",
    "BATCH_DIR = Path(\"BatchProcess\")\n",
    "ORIGINAL = \"original.jpeg\"\n",
    "img_path = Path(BATCH_DIR, ORIGINAL)\n",
    "old = str(img_path)\n",
    "old_name = str(img_path.name)\n",
    "new_name = old_name.rstrip(str(img_path.suffix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141812970 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    }
   ],
   "source": [
    "# load the image and convert to grayscale\n",
    "new_img = Image.open(img_path).convert(\"L\") # L is grayscale or \"luminance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save it as a JPG\n",
    "JPG_IMG = new_name+\".jpg\"\n",
    "name = path.join(BATCH_DIR, JPG_IMG)\n",
    "new_img.save(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 141812970 bytes, downscaled: 1417422 bytes\n"
     ]
    }
   ],
   "source": [
    "# downscale\n",
    "SCALE_PERCENT = 10 # percent of original size\n",
    "\n",
    "# open the JPG, not JPEG\n",
    "img_path = Path(BATCH_DIR, JPG_IMG)\n",
    "img_name = str(img_path)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# calculate new size\n",
    "width = int(img.shape[1] * SCALE_PERCENT / 100)\n",
    "height = int(img.shape[0] * SCALE_PERCENT / 100)\n",
    "new_size = (width, height)\n",
    "\n",
    "# downscale image\n",
    "DOWNSCALED = \"downscaled.jpg\"\n",
    "downscaled = cv2.resize(img, new_size, interpolation = cv2.INTER_AREA)\n",
    "file_name = str(Path(BATCH_DIR, DOWNSCALED))\n",
    "cv2.imwrite(file_name, downscaled)\n",
    "\n",
    "print(f\"Original: {img.nbytes} bytes, downscaled: {downscaled.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images may be in any rotation of 90 degrees.  \n",
    "This one happens to have the top at the left edge.\n",
    "![](BatchProcess/downscaled.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. rotate to landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the downscaled image\n",
    "img_path = Path(BATCH_DIR, DOWNSCALED)\n",
    "img = Image.open(str(img_path))\n",
    "width = img.size[0]\n",
    "height = img.size[1]\n",
    "\n",
    "# rotate to landscape if needed, don't yet know rightsideup or upsidedown\n",
    "if width < height:\n",
    "    landscaped = img.rotate(90, expand=True)\n",
    "LANDSCAPED = \"landscaped.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, LANDSCAPED))\n",
    "landscaped.save(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple rotation based on the fact that the width needs to be greater than the height.  \n",
    "This one happens to be upside down.\n",
    "![](BatchProcess/landscaped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. orient upright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template image\n",
    "# the template image was selected manually by using the GIMP editor\n",
    "TEMPLATE = \"template.jpg\"\n",
    "img_path = Path(BATCH_DIR, TEMPLATE)\n",
    "template = str(img_path)\n",
    "template_img = cv2.imread(template, 1) #1 is grayscale enum flag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template is the image that is being searched for in another image.  \n",
    "The template I am searching for is this \"x\" which is unique in a broad area of the image.\n",
    "![](BatchProcess/template.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load target image\n",
    "img_path = Path(BATCH_DIR, LANDSCAPED)\n",
    "target = str(img_path)\n",
    "target_img = cv2.imread(target, 1) #1 is grayscale enum flag\n",
    "\n",
    "# find these dimensions in GIMP\n",
    "#     cropping box to reduce target search area, looking for template\n",
    "left = 845\n",
    "top = 790\n",
    "right = left + 100\n",
    "bottom = top + 100\n",
    "\n",
    "# get the target image area from the template to reduce computational expense\n",
    "#    crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "target_search_area = target_img[top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template match score: 165\n"
     ]
    }
   ],
   "source": [
    "# calculate the likelihood of a match\n",
    "method = cv2.TM_SQDIFF_NORMED  \n",
    "result = cv2.matchTemplate(template_img, target_search_area, method) \n",
    "\n",
    "# minimum squared difference\n",
    "#    image similarity score is maxVal, which is what I need\n",
    "mn, maxVal, mnLoc, maxLoc = cv2.minMaxLoc(result)  \n",
    "\n",
    "# exaggerate the values to make it easier to set a cutoff point\n",
    "score = round((maxVal*100)**2)\n",
    "print(f\"Template match score: {score}\")\n",
    "\n",
    "# flip and save in place\n",
    "# 600 points seems to be a good cutoff, arbitrarily chosen for now\n",
    "if score < 600:\n",
    "    RIGHT_SIDE_UP = \"rightSideUp.jpg\"\n",
    "    rightsideup = cv2.rotate(target_img, cv2.ROTATE_180)\n",
    "    file_name = str(Path(BATCH_DIR, RIGHT_SIDE_UP))\n",
    "    cv2.imwrite(file_name, rightsideup)\n",
    "else:\n",
    "    # no need to rotate or save as its already in the correct position.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This image was upside down.  \n",
    "The template matching process gave it a low score (below 600) so it needed to be rotated right side up.  \n",
    "![](BatchProcess/rightSideUp.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. deskew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Angle skew: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "img_path = Path(BATCH_DIR, RIGHT_SIDE_UP)\n",
    "img = cv2.imread(str(img_path))\n",
    "\n",
    "# convert to grayscale, flip foreground and background\n",
    "#    foreground is now \"white\" and the background is \"black\"\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.bitwise_not(gray)\n",
    "\n",
    "# threshold the image, setting all foreground pixels to 255 and all background pixels to 0\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# grab the (x, y) coordinates of all pixel values that are greater than zero, then use these coordinates to\n",
    "#    compute a rotated bounding box that contains all coordinates\n",
    "coords = np.column_stack(np.where(thresh > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "# the `cv2.minAreaRect` function returns values in the range [-90, 0); as the rectangle rotates clockwise the\n",
    "#    returned angle trends to 0 -- in this special case we need to add 90 degrees to the angle\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "\n",
    "# otherwise, just take the inverse of the angle to make it positive\n",
    "else:\n",
    "    angle = -angle\n",
    "print(f\"Angle skew: {angle}\")\n",
    "\n",
    "# rotate the image to deskew it\n",
    "(h, w) = img.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "DESKEWD = \"deskewd.jpg\"\n",
    "deskewd = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "deskewd_name = str(Path(BATCH_DIR, DESKEWD))\n",
    "cv2.imwrite(deskewd_name, deskewd)\n",
    "\n",
    "CLEAN_DESKEWD = \"cleanDeskewd.jpg\"\n",
    "clean_deskewd = deskewd.copy() # for use later, without the contour lines drawn in...\n",
    "clean_deskewd_name = str(Path(BATCH_DIR, CLEAN_DESKEWD))\n",
    "cv2.imwrite(clean_deskewd_name, deskewd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, this image was not skewed... Need to try it on a badly skewed image.  \n",
    "![](BatchProcess/deskewd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. crop to first outer edges using Canny outlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a reduce noise while preserving boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load image\n",
    "img_path = Path(BATCH_DIR, DESKEWD)\n",
    "file_name = str(img_path)\n",
    "uppercase_img = cv2.imread(file_name)\n",
    "\n",
    "# convert to grayscale\n",
    "grayscaled = cv2.cvtColor(uppercase_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# bilateralFilter reduces noise while preserving boundaries\n",
    "bilateral_filtered = cv2.bilateralFilter(grayscaled, 11, 17, 17)\n",
    "BILATERAL_FILTERED = \"bilateralFiltered.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, BILATERAL_FILTERED))\n",
    "cv2.imwrite(file_name, bilateral_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't look like much has changed, but the \"noise\" was reduced.\n",
    "![](BatchProcess/bilateralFiltered.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b invert the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invert the image for making bounding boxes\n",
    "BILATERAL_FILTER_INVERTED = \"bilateralFilteredInverted.jpg\"\n",
    "bilateral_filter_inverted = cv2.bitwise_not(gray)\n",
    "file_name = str(Path(BATCH_DIR, BILATERAL_FILTER_INVERTED))\n",
    "cv2.imwrite(file_name, bilateral_filter_inverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverting the black and white helps the Canny function find the edges.\n",
    "With the image inverted, it is easier to see that the noise was reduced.  \n",
    "If you zoom in on the original image, you would see where the black printer ink scatters around the characters a litte.\n",
    "![](BatchProcess/bilateralFilteredInverted.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5c find the edges with Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get edges\n",
    "CANNY = \"canny.jpg\"\n",
    "canny_edges = cv2.Canny(bilateral_filter_inverted, 30, 200)\n",
    "file_name = str(Path(BATCH_DIR, CANNY))\n",
    "cv2.imwrite(file_name, canny_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canny function produced white lines where if found the edges.  \n",
    "If you look closely, you can see that the lines that make the characters and borders are thick enough that the Canny function produced two lines; one for each edge of every line of ink in the original image.\n",
    "![](BatchProcess/canny.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5d get the contours of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contours found: 10\n",
      "Length of first contour: 8\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# find contours in the edged image, keep only the largest ones, and initialize our screen contour\n",
    "contours = cv2.findContours(canny_edges.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours = imutils.grab_contours(contours) # convenience function (really simple, see https://github.com/jrosebr1/imutils/blob/master/imutils/convenience.py)\n",
    "contours = sorted(contours, key = cv2.contourArea, reverse=True)[:10]\n",
    "print(f\"Contours found: {len(contours)}\")\n",
    "print(f\"Length of first contour: {len(contours[0])}\")\n",
    "print(type(contours))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "screenCnt = None\n",
    "# loop over our contours\n",
    "for c in contours:\n",
    "    # approximate the contour\n",
    "    epsilon = 0.015 * cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, epsilon, True)\n",
    "    \n",
    "    # if our approximated contour has four points, then we can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv colors, for convenience\n",
    "BLUE = (255, 0, 0)\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "BLACK = (0, 0, 0)\n",
    "PURPLE = (255, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed in the deskewd image\n",
    "CONTOURED = \"contoured.jpg\"\n",
    "contoured = cv2.drawContours(deskewd, contours, -1, GREEN, 1)\n",
    "file_name = str(Path(BATCH_DIR, CONTOURED))\n",
    "cv2.imwrite(file_name, contoured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the current parameters for the Canny function didn't produce what I expected (intended), I think it is still of use as it found the edges of the boxes that I will need to crop out.\n",
    "![](BatchProcess/contoured.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5e get the edges of the intended cropping area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience functions\n",
    "def four_corners(box):\n",
    "    xs = [el[0][0] for el in box]\n",
    "    ys = [el[0][1] for el in box]\n",
    "    x_min = min(xs)\n",
    "    x_max = max(xs)\n",
    "    y_min = min(ys)\n",
    "    y_max = max(ys)\n",
    "    return (x_min, x_max, y_min, y_max)\n",
    "\n",
    "def area(corners):\n",
    "    return (corners[1] - corners[0]) * (corners[3] - corners[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'area': 54918, 'corners': (577, 1063, 602, 715)},\n",
      " 1: {'area': 56440, 'corners': (577, 1241, 326, 411)},\n",
      " 2: {'area': 54805, 'corners': (578, 1063, 602, 715)},\n",
      " 3: {'area': 76647, 'corners': (361, 1242, 75, 162)},\n",
      " 4: {'area': 49306, 'corners': (625, 1179, 199, 288)},\n",
      " 5: {'area': 55518, 'corners': (577, 1064, 450, 564)},\n",
      " 6: {'area': 37825, 'corners': (90, 535, 326, 411)},\n",
      " 7: {'area': 27048, 'corners': (579, 1062, 507, 563)},\n",
      " 8: {'area': 48960, 'corners': (92, 668, 202, 287)},\n",
      " 9: {'area': 41140, 'corners': (757, 1241, 326, 411)}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "boxes = {}\n",
    "for contour in contours:\n",
    "    box = contours.index(contour)\n",
    "    corners = four_corners(contour)\n",
    "    boxes[box] = {\"area\": area(corners), \"corners\": corners}\n",
    "\n",
    "pprint(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 1242 75 715\n"
     ]
    }
   ],
   "source": [
    "# the minmax across all the box corners\n",
    "xmin = min([values[\"corners\"][0] for box, values in boxes.items()])\n",
    "xmax = max([values[\"corners\"][1] for box, values in boxes.items()])\n",
    "ymin = min([values[\"corners\"][2] for box, values in boxes.items()])\n",
    "ymax = max([values[\"corners\"][3] for box, values in boxes.items()])\n",
    "\n",
    "print(xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the four extremes of the first contour on the deskewd image, not the cropped image\n",
    "#    This step is not needed, but I want to include it to emphasize/illustrate the point about finding the 4 corners using Canny's help\n",
    "upper_left = (xmin, ymin)\n",
    "lower_left = (xmin, ymax)\n",
    "upper_right = (xmax, ymin)\n",
    "lower_right = (xmax, ymax)\n",
    "\n",
    "radius = 10\n",
    "thickness = -1 # negative for filled circle\n",
    "\n",
    "four_corners = cv2.circle(deskewd, upper_left, radius, RED, thickness)\n",
    "four_corners = cv2.circle(deskewd, upper_right, radius, GREEN, thickness)\n",
    "four_corners = cv2.circle(deskewd, lower_left, radius, BLUE, thickness)\n",
    "four_corners = cv2.circle(deskewd, lower_right, radius, BLACK, thickness)\n",
    "FOUR_CORNERS = \"fourCorners.jpg\"\n",
    "file_name = str(Path(BATCH_DIR, FOUR_CORNERS))\n",
    "cv2.imwrite(file_name, four_corners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the image before the cropping.  The four dots show where the corners were calculated using the help of Canny.\n",
    "![](BatchProcess/fourCorners.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crop the image using the minmax of all the contours\n",
    "left = xmin\n",
    "top = ymin\n",
    "right = xmax\n",
    "bottom = ymax\n",
    "\n",
    "# get the target image from the template\n",
    "#     crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "CROPPED = \"cropped.jpg\"\n",
    "cropped = deskewd[top:bottom, left:right]\n",
    "file_name = str(Path(BATCH_DIR, CROPPED))\n",
    "cv2.imwrite(file_name, cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the image after cropping using the contours found with the help of Canny.  \n",
    "You can see that the edges have been cropped very close to the new boundaries and that the unwanted text at the bottom of the image was removed, too.\n",
    "![](BatchProcess/cropped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5f crop the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLEANED_CROPPED = \"cleanCropped.jpg\"\n",
    "cropped = clean_deskewd[top:bottom, left:right]\n",
    "file_name = str(Path(BATCH_DIR, CLEANED_CROPPED))\n",
    "cv2.imwrite(file_name, cropped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the cropped image without the contours drawn in.  \n",
    "From this image, I can slice it up using coordinates found using GIMP.\n",
    "\n",
    "![](BatchProcess/cleanCropped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. split into 8 major sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that I think that I need to crop the largest area of usable content first is that is was needed to make sure the images are aligned and sized properly for the following stages.  \n",
    "From this point, I can just apply a template slicing to the sections to divide everything into 8 major pieces.  \n",
    "Then, on each major piece, assuming the previous steps were successful in aligning everything properly, I can run step 5 (cropping using Canny) again on each of the smaller pieces to maintain the proper sizing and alignment on each smaller piece.  \n",
    "Finally, I can use another template slicing specific to each of the 8 sections to extract the desired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
