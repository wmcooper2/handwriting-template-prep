{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from os import path\n",
    "import numpy as np\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "IMG_DIR = Path(\"SingleImageProcess\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_jpg(img, save_to):\n",
    "#     RGB = \"RGB\"\n",
    "    BW = \"L\"\n",
    "    old = str(img) #img is a path\n",
    "    old_name = str(img.name)\n",
    "    new_name = old_name.rstrip(str(img.suffix))\n",
    "    new_img = Image.open(img).convert(BW)\n",
    "    name = path.join(save_to, new_name+\".jpg\")\n",
    "    new_img.save(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. setup and convert images to jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wandalcooper/Library/Python/3.7/lib/python/site-packages/PIL/Image.py:2800: DecompressionBombWarning: Image size (141812970 pixels) exceeds limit of 89478485 pixels, could be decompression bomb DOS attack.\n",
      "  DecompressionBombWarning,\n"
     ]
    }
   ],
   "source": [
    "# ensure saved as JPG, from JPEG and PNG\n",
    "img = Path(IMG_DIR, \"original.jpeg\")\n",
    "save_as_jpg(img, IMG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/original.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. rotate images to landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = Path(IMG_DIR, \"original.jpg\")\n",
    "actual_img = Image.open(str(image_path))\n",
    "width = actual_img.size[0]\n",
    "height = actual_img.size[1]\n",
    "\n",
    "# rotate to landscape if needed, don't yet know up or down\n",
    "if width < height:\n",
    "    rotated = actual_img.rotate(90, expand=True)\n",
    "rotated_name = str(Path(IMG_DIR, \"rotated.jpg\"))\n",
    "rotated.save(rotated_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/rotated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ensure pictures right-side up with template search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(template, target):\n",
    "    method = cv2.TM_SQDIFF_NORMED  \n",
    "    result = cv2.matchTemplate(template, target, method) \n",
    "\n",
    "    # minimum squared difference\n",
    "    # image similarity score is maxVal\n",
    "    mn, maxVal, mnLoc, maxLoc = cv2.minMaxLoc(result)  \n",
    "\n",
    "    # exaggerate the values to make it easier to set a cutoff point\n",
    "    return (maxVal*100)*(maxVal*100) # times 100 and squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load images\n",
    "TEMPLATE = \"template.jpg\"\n",
    "template_img = cv2.imread(TEMPLATE, 1) #1 is grayscale enum flag\n",
    "\n",
    "img_path = Path(IMG_DIR, \"rotated.jpg\")\n",
    "test = str(img_path)\n",
    "test_img = cv2.imread(test, 1) #1 is grayscale enum flag\n",
    "\n",
    "# cropping box to reduce search area for target template\n",
    "left = 8500\n",
    "top = 8000\n",
    "right = left + 700\n",
    "bottom = top + 700\n",
    "\n",
    "# get the target image from the template\n",
    "# crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "cropped_img = test_img[top:bottom, left:right]\n",
    "score = round(find_match(template_img, cropped_img))\n",
    "\n",
    "# flip and save in place\n",
    "# 600 points seems to be a good cutoff\n",
    "if score < 600:\n",
    "    upright_image = cv2.rotate(test_img, cv2.ROTATE_180)\n",
    "    upright_name = str(Path(IMG_DIR, \"upright.jpg\"))\n",
    "\n",
    "cv2.imwrite(upright_name, upright_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/upright.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. crop off margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cropping box to reduce search area for target template\n",
    "left = 850\n",
    "top = 710\n",
    "right = 12560\n",
    "bottom = 7300\n",
    "\n",
    "img_path = Path(IMG_DIR, \"upright.jpg\")\n",
    "file_name = str(img_path)\n",
    "img = cv2.imread(file_name, 1) #1 is grayscale enum flag        \n",
    "cropped_img = img[top:bottom, left:right]\n",
    "\n",
    "name = str(Path(IMG_DIR, \"cropped.jpg\"))\n",
    "cv2.imwrite(name, cropped_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/cropped.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. downscale images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped.jpg: (6590, 11710, 3), resized.jpg: (659, 1171, 3)\n"
     ]
    }
   ],
   "source": [
    "SCALE_PERCENT = 10 # percent of original size\n",
    "\n",
    "img_path = Path(IMG_DIR, \"cropped.jpg\")\n",
    "img_name = str(img_path)\n",
    "img = cv2.imread(img_name, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# calculate new size\n",
    "width = int(img.shape[1] * SCALE_PERCENT / 100)\n",
    "height = int(img.shape[0] * SCALE_PERCENT / 100)\n",
    "new_size = (width, height)\n",
    "\n",
    "# resize image\n",
    "resized = cv2.resize(img, new_size, interpolation = cv2.INTER_AREA)\n",
    "resized_name = str(Path(IMG_DIR, \"resized.jpg\"))\n",
    "cv2.imwrite(resized_name, resized)\n",
    "\n",
    "print(f\"cropped.jpg: {img.shape}, resized.jpg: {resized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/resized.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. deskew images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load(img):\n",
    "    # load the image from disk\n",
    "    image = cv2.imread(str(img))\n",
    "\n",
    "    # convert to grayscale, flip foreground and background\n",
    "    # foreground is now \"white\" and the background is \"black\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.bitwise_not(gray)\n",
    "\n",
    "    # threshold the image, setting all foreground pixels to 255 and all background pixels to 0\n",
    "    return image, cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\n",
    "def deskew(image, angle):\n",
    "    # rotate the image to deskew it\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# load and get threshold\n",
    "img_path = Path(IMG_DIR, \"resized.jpg\")\n",
    "image, thresh = load(img_path)\n",
    "\n",
    "# grab the (x, y) coordinates of all pixel values that\n",
    "# are greater than zero, then use these coordinates to\n",
    "# compute a rotated bounding box that contains all\n",
    "# coordinates\n",
    "coords = np.column_stack(np.where(thresh > 0))\n",
    "angle = cv2.minAreaRect(coords)[-1]\n",
    "\n",
    "# the `cv2.minAreaRect` function returns values in the\n",
    "# range [-90, 0); as the rectangle rotates clockwise the\n",
    "# returned angle trends to 0 -- in this special case we\n",
    "# need to add 90 degrees to the angle\n",
    "if angle < -45:\n",
    "    angle = -(90 + angle)\n",
    "\n",
    "# otherwise, just take the inverse of the angle to make it positive\n",
    "else:\n",
    "    angle = -angle\n",
    "\n",
    "deskewd = deskew(image, angle)\n",
    "deskewd_name = str(Path(IMG_DIR, \"deskewd.jpg\"))\n",
    "cv2.imwrite(deskewd_name, deskewd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/deskewd.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. slice the images into 8 parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CroppingTemplate:\n",
    "    def __init__(self):\n",
    "        self.image_file = None  # posix path\n",
    "        self.img = None  # actual image\n",
    "        self.counter = 1\n",
    "        self.dest_dir = \"./major_pieces\"\n",
    "        \n",
    "        self.left = 0\n",
    "        self.x1 = 330\n",
    "        self.x2 = 470\n",
    "        self.x3 = 990\n",
    "        self.right = None  # set in self.load()\n",
    "        \n",
    "        self.top = 0\n",
    "        self.y1 = 110\n",
    "        self.y2 = 235\n",
    "        self.y3 = 360\n",
    "        self.y4 = 510\n",
    "        self.bottom = None  # set in self.load()\n",
    "\n",
    "#     def load(self):\n",
    "#         self.img = Image.open(str(self.image_file))\n",
    "#         self.right = self.img.size[0]  # image width\n",
    "#         self.bottom = self.img.size[1]  # image height\n",
    "        \n",
    "#         # need right and bottom values before setting the section boxes\n",
    "#         self.setup_sections()\n",
    "\n",
    "#     def crop_all(self):\n",
    "#         for section in self.major_sections:\n",
    "#             for dir_name, box in section.items():\n",
    "#                 cropped_img = self.img.crop((box[\"left\"], box[\"top\"], box[\"right\"], box[\"bottom\"]))\n",
    "#                 file_name = path.join(self.dest_dir, dir_name, str(self.counter)+\".jpg\")\n",
    "#                 cropped_img.save(file_name)\n",
    "#         self.counter += 1\n",
    "        \n",
    "        \n",
    "    # This method was adapted from the original, just for this notebook\n",
    "    def single_image_process(self):\n",
    "        self.img = Image.open(str(self.image_file))\n",
    "        self.right = self.img.size[0]  # image width\n",
    "        self.bottom = self.img.size[1]  # image height\n",
    "        self.setup_sections()\n",
    "        \n",
    "        # crop out the parts based on the (manually set) template's dimensions\n",
    "        for section in self.major_sections:\n",
    "            for dir_name, box in section.items():\n",
    "                cropped_img = self.img.crop((box[\"left\"], box[\"top\"], box[\"right\"], box[\"bottom\"]))\n",
    "                file_name = path.join(\"SingleImageProcess\", dir_name+\".jpg\")\n",
    "                print(\"file name: \", file_name)\n",
    "                cropped_img.save(file_name)\n",
    "        \n",
    "    def setup_sections(self):\n",
    "        # these are the box boundaries for each section, manually set\n",
    "        self.major_sections = [\n",
    "            {\"uppercase\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.top,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y1}\n",
    "            },\n",
    "            {\"lowercase\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y1,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y2}\n",
    "            },\n",
    "            {\"digits\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y2,\n",
    "                \"right\": self.x2,\n",
    "                \"bottom\": self.y3}\n",
    "            },\n",
    "            {\"punctuation\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y2,\n",
    "                \"right\": self.right,\n",
    "                \"bottom\": self.y3}\n",
    "            },\n",
    "            {\"sent1\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y3,\n",
    "                \"right\": self.x1,\n",
    "                \"bottom\": self.y4}\n",
    "            },\n",
    "            {\"sent2\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y3,\n",
    "                \"right\": self.x3,\n",
    "                \"bottom\": self.y4}\n",
    "            },\n",
    "            {\"sent3\": {\n",
    "                \"left\": self.left,\n",
    "                \"top\": self.y4,\n",
    "                \"right\": self.x1,\n",
    "                \"bottom\": self.bottom}\n",
    "            },\n",
    "            {\"sent4\": {\n",
    "                \"left\": self.x2,\n",
    "                \"top\": self.y4,\n",
    "                \"right\": self.x3,\n",
    "                \"bottom\": self.bottom}\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name:  SingleImageProcess/uppercase.jpg\n",
      "file name:  SingleImageProcess/lowercase.jpg\n",
      "file name:  SingleImageProcess/digits.jpg\n",
      "file name:  SingleImageProcess/punctuation.jpg\n",
      "file name:  SingleImageProcess/sent1.jpg\n",
      "file name:  SingleImageProcess/sent2.jpg\n",
      "file name:  SingleImageProcess/sent3.jpg\n",
      "file name:  SingleImageProcess/sent4.jpg\n"
     ]
    }
   ],
   "source": [
    "# extract major sections from each image\n",
    "img_path = Path(IMG_DIR, \"deskewd.jpg\")\n",
    "cropper = CroppingTemplate()\n",
    "cropper.image_file = img_path\n",
    "cropper.single_image_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uppercase\n",
    "![](SingleImageProcess/uppercase.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercase\n",
    "![](SingleImageProcess/lowercase.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digits\n",
    "![](SingleImageProcess/digits.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Punctuation\n",
    "![](SingleImageProcess/punctuation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 1\n",
    "![](SingleImageProcess/sent1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 2\n",
    "![](SingleImageProcess/sent2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 3\n",
    "![](SingleImageProcess/sent3.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence 4\n",
    "![](SingleImageProcess/sent4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. extract individual boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path(IMG_DIR, \"uppercase.jpg\")\n",
    "test_file = str(img_path)\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(test_file)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# bilateralFilter reduces noise while preserving boundaries\n",
    "gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "# invert the image for making bounding boxes\n",
    "inverted = cv2.bitwise_not(gray)\n",
    "\n",
    "# get edges\n",
    "# edged = cv2.Canny(gray, 30, 200)\n",
    "edged = cv2.Canny(inverted, 30, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the edged image, keep only the largest\n",
    "# ones, and initialize our screen contour\n",
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:10]\n",
    "screenCnt = None\n",
    "# loop over our contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.015 * peri, True)\n",
    "    # if our approximated contour has four points, then\n",
    "    # we can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.drawContours(img, screenCnt, -1, (0, 255, 0), 3)\n",
    "boxed_image = cv2.drawContours(img, cnts, -1, (0, 255, 0), 1)\n",
    "boxed_name = str(Path(IMG_DIR, \"boxed.jpg\"))\n",
    "cv2.imwrite(boxed_name, boxed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](SingleImageProcess/boxed.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
