{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crop images with pillow:  \n",
    "https://pillow.readthedocs.io/en/stable/reference/Image.html#PIL.Image.Image.crop  \n",
    "https://www.geeksforgeeks.org/python-pil-image-crop-method/  \n",
    "\n",
    "Convert pillow image object to numpy array (ndarray):  \n",
    "https://stackoverflow.com/questions/384759/how-to-convert-a-pil-image-into-a-numpy-array  \n",
    "\n",
    "Calculating image similarity score:  \n",
    "https://answers.opencv.org/question/8890/calculating-a-template-matching-similarity-score/\n",
    "\n",
    "Convert pillow image to grayscale:  \n",
    "https://stackoverflow.com/questions/12201577/how-can-i-convert-an-rgb-image-into-grayscale-in-python  \n",
    "\n",
    "Issue when trying with BW instead of RGB:  \n",
    "https://stackoverflow.com/questions/32592950/python-opencv-template-matching-error  \n",
    "\n",
    "Crop opencv image:  \n",
    "https://stackoverflow.com/questions/15589517/how-to-crop-an-image-in-opencv-using-python  \n",
    "\n",
    "Reading image in opencv:  \n",
    "https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56  \n",
    "\n",
    "Opencv file reading flag enums:  \n",
    "https://docs.opencv.org/master/d4/da8/group__imgcodecs.html#ga61d9b0126a3e57d9277ac48327799c80  \n",
    "\n",
    "Rotate opencv image:  \n",
    "https://note.nkmk.me/en/python-opencv-numpy-rotate-flip/  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from itertools import tee\n",
    "from os import path\n",
    "import cv2\n",
    "\n",
    "# IMG_SRC_DIR = \"./rotated\"\n",
    "IMG_SRC_DIR = \"./jpg\"\n",
    "TEMPLATE = \"template.jpg\"\n",
    "template_img = cv2.imread(TEMPLATE, 1) #1 is grayscale enum flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match(template, target):\n",
    "    method = cv2.TM_SQDIFF_NORMED  \n",
    "    result = cv2.matchTemplate(template, target, method) \n",
    "\n",
    "    # minimum squared difference\n",
    "    # image similarity score is maxVal\n",
    "    mn, maxVal, mnLoc, maxLoc = cv2.minMaxLoc(result)  \n",
    "\n",
    "    # exaggerate the values to make it easier to set a cutoff point\n",
    "    return (maxVal*100)*(maxVal*100) # times 100 and squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(img, img_path, src_dir):\n",
    "    old_name = str(img_path.name)\n",
    "    name = path.join(src_dir, old_name)\n",
    "    cv2.imwrite(name, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jpg/alphabet00794.jpg 768\n",
      "jpg/alphabet00793.jpg 378\n",
      "jpg/alphabet00787.jpg 400\n",
      "jpg/alphabet00368.jpg 319\n",
      "jpg/alphabet00369.jpg 300\n",
      "jpg/alphabet00786.jpg 389\n",
      "jpg/alphabet00792.jpg 369\n",
      "jpg/alphabet00009.jpg 354\n",
      "jpg/alphabet00790.jpg 400\n",
      "jpg/alphabet00791.jpg 380\n",
      "jpg/alphabet00785.jpg 397\n",
      "jpg/alphabet00008.jpg 361\n",
      "jpg/alphabet00005.jpg 363\n",
      "jpg/alphabet00788.jpg 408\n",
      "jpg/alphabet00367.jpg 336\n",
      "jpg/alphabet00366.jpg 338\n",
      "jpg/alphabet00789.jpg 369\n",
      "jpg/alphabet00010.jpg 372\n",
      "jpg/alphabet00004.jpg 370\n",
      "jpg/alphabet00006.jpg 353\n",
      "jpg/alphabet00364.jpg 317\n",
      "jpg/alphabet00365.jpg 313\n",
      "jpg/alphabet00007.jpg 386\n",
      "jpg/alphabet00003.jpg 386\n",
      "jpg/alphabet00361.jpg 357\n",
      "jpg/alphabet00360.jpg 330\n",
      "jpg/alphabet00002.jpg 366\n",
      "jpg/alphabet00362.jpg 327\n",
      "jpg/alphabet00363.jpg 323\n",
      "jpg/alphabet00001.jpg 339\n",
      "Done flipping images\n"
     ]
    }
   ],
   "source": [
    "# cropping box to reduce search area for target template\n",
    "left = 8500\n",
    "top = 8000\n",
    "right = left + 700\n",
    "bottom = top + 700\n",
    "\n",
    "# collect image paths\n",
    "gen, image_paths = tee(Path(IMG_SRC_DIR).iterdir())\n",
    "for img_path in image_paths:\n",
    "    if img_path.suffix == \".jpg\":\n",
    "        test = str(img_path)\n",
    "        test_img = cv2.imread(test, 1) #1 is grayscale enum flag\n",
    "#         crop_img = img[y:y+h, x:x+w] #opencv's x and y are flipped\n",
    "        cropped_img = test_img[top:bottom, left:right]\n",
    "        score = round(find_match(template_img, cropped_img))\n",
    "        print(str(img_path), score)\n",
    "        # 600 points seems to be a good cutoff\n",
    "        \n",
    "        # flip and save in place\n",
    "        if score < 600:\n",
    "            rotated_img = cv2.rotate(test_img, cv2.ROTATE_180)\n",
    "            save(rotated_img, img_path, IMG_SRC_DIR)\n",
    "print(\"Done flipping images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
